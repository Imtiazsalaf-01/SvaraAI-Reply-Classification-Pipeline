# SvaraAI-Reply-Classification-Pipeline

End-to-end ML pipeline for classifying email replies as positive, negative, or neutral. Implements baseline (Logistic Regression) and transformer (DistilBERT) models, evaluated with Accuracy & F1, and deployed via FastAPI /predict API with Docker support.

## ğŸ¯ Project Overview

This project implements a complete ML pipeline for email reply classification:
- **Part A**: ML/NLP Pipeline with baseline and transformer models
- **Part B**: FastAPI deployment with `/predict` endpoint  
- **Part C**: Analysis and reasoning (see `answers.md`)

## ğŸ“Š Dataset

The dataset consists of labeled email replies, categorized into:
- **Positive**: Interested, excited, wants to proceed
- **Negative**: Not interested, wants to be removed  
- **Neutral**: Asking questions, requesting information

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- pip

### Installation & Setup

1. **Install dependencies**
```bash
pip install -r requirements.txt
```

2. **Run the complete ML pipeline**
```bash
python notebook.py
```
This will:
- Load and preprocess the dataset
- Train baseline model (TF-IDF + Logistic Regression)
- Optionally train transformer model (DistilBERT)
- Evaluate and compare models
- Save trained models

3. **Start the API server**
```bash
python src/app.py
```
The API will be available at `http://localhost:8000`

4. **Test the API**
```bash
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{"text": "Looking forward to the demo!"}'
```

Expected response:
```json
{
  "label": "positive",
  "confidence": 0.87
}
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ notebook.py                    # Main ML pipeline (Part A)
â”œâ”€â”€ src/
â”‚   â””â”€â”€ app.py                     # FastAPI application (Part B)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ reply_classification_dataset.csv
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ val.csv
â”‚   â””â”€â”€ test.csv
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ baseline_model.joblib      # Trained baseline model
â”‚   â””â”€â”€ transformer/               # Trained transformer model (optional)
â”œâ”€â”€ answers.md                     # Short answers (Part C)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

## ğŸ”§ API Usage

### Endpoint: POST /predict

**Input:**
```json
{
  "text": "Looking forward to the demo!"
}
```

**Output:**
```json
{
  "label": "positive",
  "confidence": 0.87
}
```

### Python Example
```python
import requests

response = requests.post(
    "http://localhost:8000/predict",
    json={"text": "This looks great, let's schedule a call!"}
)
print(response.json())
# Output: {"label": "positive", "confidence": 0.92}
```

## ğŸ“ˆ Model Performance

### Baseline Model (TF-IDF + Logistic Regression)
- **Accuracy**: ~99%
- **F1 Score**: ~99%
- **Inference Time**: ~1-5ms per sample
- **Model Size**: ~34KB

### TTransformer Model (DistilBERT) â€“ Advanced
- **Accuracy**: Typically 1-3% higher than baseline
- **Inference Time**: ~20-50ms per sample  
- **Model Size**: ~250MB

## ğŸ³ Docker Deployment

```bash
# Build the image
docker build -t reply-classifier .

# Run the container
docker run -p 8000:8000 reply-classifier
```

## ğŸ› ï¸ Development

### Running Individual Components

```bash
# Run only the ML pipeline
python notebook.py

# Run only the API
python src/app.py

# Check API documentation
# Visit http://localhost:8000/docs
```

### Model Selection

The API automatically uses the best available model:
1. Transformer model (if available in `models/transformer/`)
2. Baseline model (fallback)

## ğŸ“‹ Assignment Deliverables

âœ… **Part A - ML Pipeline**: `notebook.py`
- Data preprocessing and exploration
- Baseline model training (TF-IDF + Logistic Regression)
- Transformer model training (DistilBERT)
- Model evaluation and comparison

âœ… **Part B - API Deployment**: `src/app.py`  
- FastAPI service with `/predict` endpoint
- JSON input/output as specified
- Dockerfile for containerization

âœ… **Part C - Analysis**: `answers.md`
- Short answer questions about model improvement, bias prevention, and prompt design

## ğŸš¨ Troubleshooting

**Model not found error:**
```bash
# Make sure to run the ML pipeline first
python notebook.py
```

**API not starting:**
```bash
# Check if port 8000 is available
python src/app.py
```

**Transformer training issues:**
- Comment out transformer training in `notebook.py` if you have limited resources
- The baseline model alone achieves excellent performance

## ğŸ“š Key Features

- **High Performance**: 99% accuracy on test set
- **Fast Inference**: Sub-5ms predictions with baseline model
- **Production Ready**: FastAPI with automatic documentation
- **Containerized**: Docker support for easy deployment
- **Extensible**: Easy to add new models or features

---

**ğŸ“Œ Assignment Alignment: Fully implements all deliverables (Part A, Part B, Part C).  
**Estimated Runtime**: 5-10 minutes for full pipeline  
**API Documentation**: Available at `http://localhost:8000/docs` when running
